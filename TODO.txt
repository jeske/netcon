***********************************
*
* Netcon - Network Condition Monitoring Tool
*
*      ---  TODO  ---
*

.) Bugs!!@!@@!!!
   - total disk space seems to be changing, why? is it "free"?
   - changing a trigger source leaves old trigger errors alive

0) Basic bringup

   - (done) database schema/odb
   - (done) error/incident manager
   - (done) basic test               #  test.py 
   - (done) first webpage            #  http://c1.neotonic.com/netcon/index.py
   - (done) first agent monitor      #  Disk monitor
   - (done) agent cron mode
   - (done) agent data-submission
   - (done) basic trigger config
   - (done) basic incident notifications
   - (done) basic ping agent w/ping host configuration
   - (done) basic queue directory watcher w/dir configuration
   - (done) basic role creation/machine assignment
   - (done) setup entire neotonic QOS config (see below)                
   - (done) view data history/service info
   - (done) triggers/errors should show curent state on index page (red/green)
   - (done) data graph
   - (done) resolve/close incident

   - replace QOS!!!
     - (done) split items onto new incidents (disk/swap->new incident)
     - (done) incident states (new,viewed,watch,acknowledge,resolved)
     - report on agent checkin failure!
     - incident notes
     - expire trigger data from errors which are too old
     - improve notification format

   - cleanup
     - show how recent the collected data is (relative)
     - change process monitor to re.search()
     - index page should show the service namepath/type
     - agentConfigPage : to setup what agents are running on a machine
     - remove machines/agents/services from main page (overview)
     - add units ( disk/inodes:cur/kb ? )
     - delete trigger
     - expire state which was not provided again during the last agent checkin

   - disk space trend
     - progressive linear trends
     - linear regression ?
     - http://www.scipy.org/site_content/tutorials/show_doc?input_file=node20.html
     - http://www.scipy.org/site_content/tutorials/show_doc?input_file=index.html

   - netcon user accounts
     - currently active user support
     - audit log of config changes
     - (see notification schedule/escelation)

   - instant data updates
     - change trigger, rerun that trigger
     - change trigger source, set to zero for old source.
     - show the old and new trigger results over time to compare
       before save...

   - switch to XML for client/server
     - client -> server : list of monitors, config data for each monitor
     - server -> client : structured configuration

   - notifications
     - while netcon does not have connectivity, it should not
       send notifications (single alert)
     - add trigger "time to severity" (5m->info,30m->critical)
       - how is this different for triggers than for wall time?
     - ex
       - upn network goes down at night -- no pages
       - our upn switch goes down -- at night 30m, day 5m
       - gator.trakken.com is down -- page in 5m
       - when everything goes good, send page
     - once the incident is viewed, raise freq to 30m
     - quick-notes "I'm calling navisite"
     - when the incident is watch w/note, set watch timeout..
     - when the incident is ack, stop paging

   - agent frequency
     - control agent freq (ping-1m, innodb-30m)
     - control data-summarization (ping time - 10m)

   - improve incident details
     - more specific error info
      - types of error histories:
        - went bad and is bad
          - time of error creation
        - went bad and is good
          - time of error creation
          - time of good
        - went bad and is fluctuation
          - time of error creation
          - know that it's fluctuating

   - fix graphs to use time properly
     - should align time for all graphs on a page!
     - maybe we should just use one big graph for most pages

   - new data addition optimization (txn?)
   - show how many minutes/seconds ago the data-collection was on index

1) Edge Cases

   - when changing triggers we need to do something with trigger state
     since old state values get "stuck" if you remove the trigger.
     (manually clear? automatically clear? rerun?)
   - method to trigger ncsrv.py re-evaluation ??

2) Agent Data Monitors and Features

   - (done) disk usage 
   - (done) memory usage
   - (done) cpu usage
   - (done) tcp check (hack)
   - (done) innodbtablespace
   - (done) directory/queue count
   - (done) process state
   - tcp chat (connect,request,response)
   - ping/packet loss monitor
   - extended http/https (apache server status?)
   - extended dns
   - RAID status (3ware, promise)
   - oracletablespace
   - domain check
     - automatically check for secondary DNS, issue warning
     - check for redundant MX, RCPT to acceptance, issue warning
   - snmp
   - smtp address delivery (dns,smtp,rcpt to)
   - agent daemon run-loop

3) Server UI

   - incident details / notes
   - resolve incident / watch timeout
   - search past incidents, search knowledge information
   - configuration
     - machine hierarchy
     - server-side per-agent state configuration
     - machine roles
     - role triggers
   - machine view
   - role view
   - stat/source history (data/graph)

4) Notification System

   - multiple levels of triggers, 'info', 'warning', 'error', 'failure'
   - ex: wait longer to notify at night (in case it resolves), for example,
         a network failure might have longer timeouts at night
   - ex: automatic cyclic shift descriptions, pick period 
         (daily,weekly,monthly,etc), then fill in slots on that period
   - ex: incident/notification domains - match into incident domains based
         on service type (network, vs machine, vs db, vs service), or based on
         machine subtree. Notification list is different for different incident
         domains.
   - ex: priority fallbacks for non-responsive oncall personel
         (i.e. 5min : alert of problem, 10min : alert of non-response to problem,
               15min : alert of next on-call person)

   - need to address:
       - selection
         - rotation
         - escelation
       - urgency
         - method
         - frequency

   - strawman 1:
       - selection    : role can select the notification group
         - rotation   : notification group has an ordered rotating
                        schedule, with a period. 
         - escelation : escelate between people in the escelation group.
                        additional "escelation notification groups" with
                        timeouts. (i.e. page the VP in 30 minutes, page the
                        CEO in 2 hours)
       - urgency      : each level indicates how urgent the response is
         - method     : info,warning -> normal, error,failure -> pager
         - frequency  : info,warning -> new incident, daily reminder
                        error,failure -> every 5 minutes

     Questions/Issues:
       - isn't the rotating notification group only for urgent
         issues? Shouldn't every get an info update?


5) Features / Designs

   - notification config/shifts/user watch/incident watch timer
   - redundant role triggers
      - ex: 10 machines in "Public UI" role, any one of them
            failing is a warning, > 40% failing is an error
   - separation of triggers/incidents by level and/or hierarchy
   - hierarchial suppression
   - 'derivative values' plugin system
      - spike detection
        - width/height of spike
        - abs, or relative to current values
        - ex: queue size jump
      - trend prediction
        - trend computation paramaters (smoothing, window, decay)
        - predict time to target value
        - ex: time to run out of disk space
           - easy to view the current window
           - sort machines by their time to run out of space
           - create basic triggers on the time (<48hours)
           - create multiple trend predictors "short term" and 
             "long term" by tuning values
      - cyclic trend prediction
        - ex: will the system have capacity tomorrow morning?
        - ex: will the system have capacity next holiday?
    - trigger based fixes...
        - ex: single webserver has really long timeouts, but
              all the other servers in the role are functioning
              normally
        - shutdown and reboot server
        - remove a server from load balancer
    - maintain other organizations of machines
        - ex, rack location, power control, serial console
        - provide a query interface so tools can use this data easily.
          - ex, "./powercycle.py c1" finds out what apc port c1 is on from netcon
            - Provide these plugin tools inside Netcon server
  - Idea: revive Brandon's old "exception browser" concept for storing
    and browsing exceptions and other state messages
  - data-resolution reduction
  - Idea: give vendors their own private access pages to see status
      for their sites. (i.e. "info about gator.trakken.com")
    
6) Neotonic QOS Config:

   Roles:
     - All: cpu,mem,disk,dir(bugs,maildir)
     - stdproc: proc (httpd,xntpd,master)
     - trkproc: proc (search_index,inject,popinject,mysqld)
     - trakdb: MyInnoTbSpc
     - trakpub: proc (public_update.py)
     - 3ware: proc 3dmd, 3w-raid
     - mailcheck: smtp c1,c2,c5,c4,c6,c8,c9,c12
     - dns: ns3,ns4
     - webcheck:  web / : neotonic.com, trakken.com,google.trakken.com,
           web unsup: c5.neotonic.com,wu.trakken.com,youwinit.trakken.com,
                      wu.trakhelp.com
     - minimailcheck: smtp c1,c2

     - "localhost mailcheck" ?

   Machines:
     - c1: All,Stdproc, mailcheck, dns, webcheck
     - c2: All, stdproc, trakproc, minimailcheck
     - c4: All, stdproc, trakproc, 3ware, trakdb
     - c5: All, stdproc, trakproc, 3ware, trakdb
     - c6: All, stdproc, trakproc, dns, trakdb
     - c7: All, stdproc, trakpub, minimailcheck
     - c8: All, stdproc, trakproc, trakdb
     - c9: All, stdproc
     - c12: All, stdproc, dns, mailcheck, webcheck
     - g3: All, stdproc, trakproc, trakdb


export CVS_RSH=ssh
cvs -d ":ext:jeske@cvs.neotonic.com:/d2/cvsroot" co -d nc_agent netcon/nc_agent
*/5 * * * * (cd /neo/nc_agent;./ncagent.py) 2>&1 >> /neo/log/ncagent.log


7) References

  - Netcool
    http://www.micromuse.com/products_sols/product_information.html
  - SMARTS
    http://www.smarts.com/

